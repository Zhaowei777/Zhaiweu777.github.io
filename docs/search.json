[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Learning Diary",
    "section": "",
    "text": "About Me\nHello! I’m Zhaowei, a student deeply passionate about art, computer science, and urban science, and an enthusiast of music and photography. I am currently pursuing a master’s degree at The Bartlett Centre for Advanced Spatial Analysis, University College London. Throughout my early education, I focused on honing my creative design and oil painting skills, dreaming of becoming an artist. I completed my Bachelor of Design at the University of Melbourne, where I also took foundational courses in artificial intelligence. During that time, I developed a basic understanding of urban planning, spatial engineering, and architecture, and realized the importance of computer science in everyday life and academia.\nThese are some works from my personal photography studio:\n\n\n\nRemote sensing, akin to an aerial photographer, captures the cities from the heavens above\n\n\nMy current research interests lie in the Internet of Things (IoT) and smart cities. I believe that improving people’s quality of life through data science and computer science is a fascinating endeavor. Remote sensing technology significantly advances urban planning by offering detailed insights into land use and environmental changes, enabling sustainable development and improved resilience against environmental challenges. This website serves as my learning diary for the CASA0027 course, reflecting on and deepening my understanding of remote sensing knowledge. I hope everyone enjoys it and I welcome any criticism or praise!\n\n\n“We can really say that we have achieved a level of remote sensing and Earth observation that we have never had before. We’re in the golden age right now with these satellites.”\n\n\n                                                    —————Tim Newman, USGS National Land Imaging Program coordinator",
    "crumbs": [
      "About Me"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Week 1 - Intro to Remote Sensing",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1 - Intro to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Week 2 - Short Presentation",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 2 - Short Presentation</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "week1.html",
    "href": "week1.html",
    "title": "1  Week 1 - Intro to Remote Sensing",
    "section": "",
    "text": "1.1 Overview\nWeek1, let’s start with a ‘simple’ question: What is remote sensing?\nNASA defined Remote sensing as an acquisition of information from a distance. In my understanding, this tech involves acquiring data about entities or regions without direct physical interaction. Typically, it is achieved by detecting and documenting energy that is either reflected or emitted, followed by the processing, analysis, and utilization of this data.\nIts implementation is through sensors mounted on various platforms: like Satellites, Airplanes (for aerial imagery), Drones and Smartphones. There are over 150 satellites in orbit equipped with sensors for remote sensing.\nOh,I see,easy one. What types of sensors are there?\nThere are mainly two types of sensors:\nActive sensors are equipped with their own illumination source, actively emitting electromagnetic waves and then measuring the backscatter that returns to the sensor. Examples like: Radar and LiDAR. Their application includes generating precise digital elevation models through the Shuttle Radar Topography Mission (SRTM), monitoring rainforest depletion via LiDAR technology, and supporting security measures with its effectiveness in marine and Arctic surveillance.\nConversely, passive sensors don’t emit anything. They rely on natural light, detecting reflected energy (in electromagnetic waves) from the sun. Examples like: Landsat series and IRS-series. The Landsat series, active for over four decades, stands as the most enduring Earth observation initiative in passive remote sensing. It provides critical insights into Earth’s climate, ecosystems, and land use changes, serving as a historical marker for environmental transformation.\nEmm, can you provide me with an example respectively makes it easy to understand?\nSure. Active sensors- your iPhone camera with the flash turned on. Passive sensor- your iPhone camera without the flash turned on OR- your eyes.\nGotcha! Next, we move to ‘Electromagnetic waves’. This reminds me of the old days when I was studying A-level physics. Time flies by, it makes me cry :( .\nAs we know most remote sensing relies on detecting and analyzing electromagnetic radiation(EMR) to gather information about objects or areas from afar without direct contact. (We are not focused on some types of remote sensing that use mechanical waves instead of electromagnetic waves like seismographs). Electromagnetic Radiation 1) consists of waves with both electric and magnetic fields that propagate through space, and 2) the electric and magnetic fields are perpendicular to each other.\nThe fundamental Formula related to EMR is:  Electromagnetic radiation (EMR) undergoes several variations before reaching a sensor, rather than being directly reflected. For example: Surface- Energy is absorbed by the surface, and Atmospheric- Energy is scattered by particles in the atmosphere, influencing the clarity and quality of the sensed data.\nThere are Three types of scattering - Rayleigh scattering occurs with particles much smaller than the wavelength of the radiation (like oxygen molecules). This phenomenon explains why the sky appears “blue” during the day and why the sea normally appears “blue”. - Mie scattering happens with particles about the same size as the wavelength (like smoke and dust). - Non-selective scattering involves particles much larger than the wavelength(like water vapour).\nBTW, 1) the moon has a black sky because there is no atmosphere- no scattering can happen. 2) The ocean usually appears blue because it absorbs blue wavelengths the least, scattering and reflecting them to the observer’s eye. 3) Active sensors like Synthetic Aperture Radar (SAR) can pass through clouds.\nCan you explain about Remotely sensed data and the four resolutions?\nOf course, I will explain to you in detail:\nRaster data is typically obtained through remote sensing; however, this varies depending on the sensor.\n4 types of resolution\n1)Spatial resolution: defines the ability to resolve spatially close objects and to identify small objects, which is expressed by Ground Sampling Distance (pixel size on the ground). The GSD is influenced by factors such as the altitude of the sensor, the sensor’s optical characteristics, and the pixel size of the sensor array. More detailed images are possible with higher spatial resolution (smaller pixel sizes), which highlights smaller features in the observed region.\nSpatial resolution (geometric) o Low resolution &gt;= 30m &lt; 300m o Medium resolution &gt;= 5 &lt; 30m o High resolution &gt;= 2m &lt; 5m o Very high resolution &lt; 2m\nFor example:\nThe Landsat 8 OLI sensor shows improved spectral resolution, indicated by the increased number of bands and narrower bandwidths (compared to Landsat 4-5 (MSS)). This improvement allows for more precise detection of different features on the Earth’s surface due to the ability to capture more specific ranges of the spectrum and differentiate between more subtle differences in reflectance.\no Panchromatic (wide bandwidth, visible range of spectrum) o Multispectral &gt;= 3 spectral bands (RGB, RGB NIR + MIR) o Hyperspectral &gt;= 30 spectral bands (lower geometric and resolution) o These images have high spectral resolution but low spatial resolution\n(Higher number of bits = higher the radiometric resolution = higher the quality of the image = higher possibility to differentiate features)\nFor example:\n8 bit = 256 possible values; 1 bit = 2 possible values\nImages above clearly illustrute that the 8-bit image has better quality than the 1-bit one.\n4)Temporal: Involves how frequently a sensor collects data of the same area. (Short revisit/reacquisition cycle = better temporal resolution)\nFor example: The satellite orbit above the UK and it won’t come back until the day after 15 days. So if the cycle is shorten to 3 days it’s better temporal resolution.\nSo much knowledge! Thank you for your summary and explanation, but I need some time to understand.\ntake your time! Next, I will review the application of remote sensing according to some literature, which will help you understand.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1 - Intro to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "2  Week 2 - Short Presentation",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 2 - Short Presentation</span>"
    ]
  },
  {
    "objectID": "week1.html#overview",
    "href": "week1.html#overview",
    "title": "1  Week 1 - Intro to Remote Sensing",
    "section": "",
    "text": "Frequency, Speed and the Wave-length\n\n\n\n\nSpectral: Describes the number and width of spectral bands that a sensor records. (more or narrower bands = better spectral resolution)\n\n\n\n\n\nImproved Spectral Resolution of Landsat 8 Instrument (OLI)\n\n\n\n\n\nRadiometric: defines the ability to resolve objects with similar reflectance (within the same wavelength)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1 - Intro to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "week3.html",
    "href": "week3.html",
    "title": "3  week 3 - corrections",
    "section": "",
    "text": "3.1 Overview\n1.1.1 Overview This week’s journey into remote sensing unveils the potential for image correction and enhancement. While corrections aim to rectify sensor, atmospheric, or terrain-induced distortions, our focus will shift towards enhancement techniques, specifically Ratio, Texture, and Principal Component Analysis (PCA), to enrich remote sensing imagery interpretation.\n1.1.2 Ratio Enhancement: The NDVI Technique Ratio enhancements exploit varying spectral signatures across materials to accentuate particular elements. The Normalised Difference Vegetation Index (NDVI) leverages red and near-infrared bands, highlighting healthy vegetation’s unique reflective properties. Below is a formula representation and its application on Cape Town’s Landsat imagery from 2022, revealing vegetation health:\nBy setting a threshold NDVI value above 0.15, the visualization emphasizes vibrant farmland north of Cape Town, with urban and aquatic regions depicted in white. Interestingly, indigenous vegetation areas like Cape Point peninsula don’t prominently feature in NDVI outputs, possibly due to seasonal variations affecting the indigenous versus agricultural vegetation contrast:\n1.1.3 Texture Analysis Texture analysis measures pixel similarity within a spatial context, offering insights into landscape homogeneity. Utilizing a grey-level co-occurrence matrix (GLCM), this technique assesses homogeneity across pixels, distinguishing highly uniform areas from those with significant variance. The resultant texture map for Cape Town illustrates the differentiation between homogenous regions (such as oceans and agricultural lands) and areas of stark contrast (e.g., the coastal interface):\n1.1.4 Principal Component Analysis PCA serves as a dimensionality reduction tool, simplifying complex, multi-band spectral data into principal components that capture the majority of data variance.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>week 3 - corrections</span>"
    ]
  },
  {
    "objectID": "week3.html#overview",
    "href": "week3.html#overview",
    "title": "3  week 3 - corrections",
    "section": "",
    "text": "NDVI\n\n\n\n\n\n\n\ncomparison",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>week 3 - corrections</span>"
    ]
  },
  {
    "objectID": "week1.html#applications",
    "href": "week1.html#applications",
    "title": "1  Week 1 - Intro to Remote Sensing",
    "section": "1.2 Applications",
    "text": "1.2 Applications\n\n\n“In science there is only physics; all the rest is stamp collecting.”\n\n\n                                                    —————William Thomson(Lord Kelvin)\n\n\nThe fundamental core of remote sensing technology is electromagnetism, the interactions of electromagnetic energy with the atmosphere and the Earth’s surface are critical in determining the quality and type of data collected. The electromagnetic spectrum highlights the diverse range of electromagnetic waves, from long radio waves to short gamma rays, and the human eye’s ability to detect only a small portion of this spectrum, known as visible light. \nPresented below are several prevalent electromagnetic waves utilized in the field of remote sensing, along with their respective applications and examples of corresponding remote sensing satellites.\n\nVisible Light and Near-Infrared: These bands are commonly used for monitoring land cover, vegetation health, urban planning, and environmental changes. Vegetation is strongly reflected in these bands, making it possible to assess the health and density of vegetation. Satellite Examples: Landsat Series: For global environmental monitoring, including agriculture, and forest coverage. Sentinel-2: Providing high-resolution images of land cover and vegetation health.\nThermal Infrared: Used for measuring surface temperature, fire detection, evapotranspiration, and sea surface temperature monitoring. Thermal infrared data can help analyze drought conditions and the urban heat island effect. Satellite Examples: MODIS: Onboard the Terra and Aqua satellites, providing global climate system observations, including surface temperature.\nMicrowave: As microwaves can penetrate clouds, dust, smoke, snow, and rain, they are ideal for satellite communication in extreme weather conditions. Microwave remote sensing is crucial for understanding global water cycles and climate change. Satellite Examples: SMAP (Soil Moisture Active Passive): A NASA satellite focused on global soil moisture measurement to help forecast floods and droughts. GRACE (Gravity Recovery and Climate Experiment) Series: To measure variations in Earth’s gravitational field and deduce changes in ice mass and groundwater storage.\nUltraviolet: Mainly used for atmospheric and solar studies, including ozone layer monitoring, solar activity observation, and air quality assessment. Satellite Examples: Aura Satellite: Carrying the OMI (Ozone Monitoring Instrument) focused on atmospheric composition and atmospheric chemistry studies.\nX-Rays and Gamma Rays: Mainly employed in the field of astronomy to investigate high-energy events in the universe, such as black holes, neutron stars, and remnants of supernovas. Satellite Examples: Chandra X-ray Observatory: For studying high-temperature objects and X-ray sources in the universe.\n\nAs we can see above, with the cornerstone of electromagnetic technology, remote sensing can be utilized across interdisciplinary fields, especially contributing significant power to urban-related studies. For urban environments, the differentiation between wavelengths allows for the identification of specific gases in the atmosphere, which can be used to monitor air quality or track the movement of atmospheric pollutants. In terms of Urban Agriculture, it enables the identification of healthy versus stressed vegetation, allowing for precise monitoring of crop health and the optimization of agricultural practices. Within the field of Urban Planning, it provides critical data for urban planning, such as land use classification and urban expansion. As for Urban Climate Studies, remote sensing data contribute to understanding and modelling climate systems and tracking changes in ice cover, sea levels, and global temperatures.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1 - Intro to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "week1.html#reflection",
    "href": "week1.html#reflection",
    "title": "1  Week 1 - Intro to Remote Sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nBased on my interest in the Internet of Things (IoT), I have developed some ideas about the relationship between remote sensing and IoT. In my view, the development of the two disciplines, remote sensing and IoT, is blurring the distance between them. Both technologies are driven by similar needs- to efficiently collect data on a large scale without requiring a lot of manpower. They have both evolved to be able to analyse data and simplify large amounts of data to make it easy to understand.\nBased on what I’ve learnt about remote sensing this week, I believe that remote sensing and the Internet of Things are essentially complementary and that they have different strengths for solving problems. Remote sensing can essentially be thought of as “external IoT”, whereas traditional IoT uses embedded or internal sensors. Combining the two offers even greater potential. For example, sensors inside an underground pipe may detect a drop in pressure at a certain cross-section, but external hyperspectral sensors can link this pressure to changes present in the ground and synthesise the root cause of the problem. The data generated by these technologies has the potential to provide a wide range of new insights, reduce costs and improve system performance.\nWith their combination, plus the utilisation of new technologies such as artificial intelligence and cloud computing. There is an opportunity for a whole host of new ways to protect critical infrastructure, preserve the environment and improve human life.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1 - Intro to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "week6.html",
    "href": "week6.html",
    "title": "6  week 6 - intro to GEE",
    "section": "",
    "text": "Mind map",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>week 6 - intro to GEE</span>"
    ]
  }
]