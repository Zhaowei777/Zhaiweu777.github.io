[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Learning Diary",
    "section": "",
    "text": "About Me",
    "crumbs": [
      "About Me"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Week 1 - Intro to Remote Sensing",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1 - Intro to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Week 2 - Short Presentation",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 2 - Short Presentation</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "week1.html",
    "href": "week1.html",
    "title": "1  Week 1 - Intro to Remote Sensing",
    "section": "",
    "text": "1.1 Overview\nWeek1, let’s start with a ‘simple’ question: What is remote sensing?\nNASA defined Remote sensing as an acquisition of information from a distance. In my understanding, this tech involves acquiring data about entities or regions without direct physical interaction. Typically, it is achieved by detecting and documenting energy that is either reflected or emitted, followed by the processing, analysis, and utilization of this data.\nIts implementation is through sensors mounted on various platforms: like Satellites, Airplanes (for aerial imagery), Drones and Smartphones. There are over 150 satellites in orbit equipped with sensors for remote sensing.\nOh,I see,easy one. What types of sensors are there?\nThere are mainly two types of sensors:\nActive sensors are equipped with their own illumination source, actively emitting electromagnetic waves and then measuring the backscatter that returns to the sensor. Examples like: Radar and LiDAR. Their application includes generating precise digital elevation models through the Shuttle Radar Topography Mission (SRTM), monitoring rainforest depletion via LiDAR technology, and supporting security measures with its effectiveness in marine and Arctic surveillance.\nConversely, passive sensors don’t emit anything. They rely on natural light, detecting reflected energy (in electromagnetic waves) from the sun. Examples like: Landsat series and IRS-series. The Landsat series, active for over four decades, stands as the most enduring Earth observation initiative in passive remote sensing. It provides critical insights into Earth’s climate, ecosystems, and land use changes, serving as a historical marker for environmental transformation.\nEmm, can you provide me with an example respectively makes it easy to understand?\nSure. Active sensors- your iPhone camera with the flash turned on. Passive sensor- your iPhone camera without the flash turned on OR- your eyes.\nGotcha! Next, we move to ‘Electromagnetic waves’. This reminds me of the old days when I was studying A-level physics. Time flies by, it makes me cry :( .\nAs we know most remote sensing relies on detecting and analyzing electromagnetic radiation(EMR) to gather information about objects or areas from afar without direct contact. (We are not focused on some types of remote sensing that use mechanical waves instead of electromagnetic waves like seismographs). Electromagnetic Radiation 1) consists of waves with both electric and magnetic fields that propagate through space, and 2) the electric and magnetic fields are perpendicular to each other.\nThe fundamental Formula related to EMR is:  Electromagnetic radiation (EMR) undergoes several variations before reaching a sensor, rather than being directly reflected. For example: Surface- Energy is absorbed by the surface, and Atmospheric- Energy is scattered by particles in the atmosphere, influencing the clarity and quality of the sensed data.\nThere are Three types of scattering - Rayleigh scattering occurs with particles much smaller than the wavelength of the radiation (like oxygen molecules). This phenomenon explains why the sky appears “blue” during the day and why the sea normally appears “blue”. - Mie scattering happens with particles about the same size as the wavelength (like smoke and dust). - Non-selective scattering involves particles much larger than the wavelength(like water vapour).\nBTW, 1) the moon has a black sky because there is no atmosphere- no scattering can happen. 2) The ocean usually appears blue because it absorbs blue wavelengths the least, scattering and reflecting them to the observer’s eye. 3) Active sensors like Synthetic Aperture Radar (SAR) can pass through clouds.\nCan you explain about Remotely sensed data and the four resolutions?\nOf course, I will explain to you in detail:\nRaster data is typically obtained through remote sensing; however, this varies depending on the sensor.\n4 types of resolution\n1)Spatial resolution: defines the ability to resolve spatially close objects and to identify small objects, which is expressed by Ground Sampling Distance (pixel size on the ground). The GSD is influenced by factors such as the altitude of the sensor, the sensor’s optical characteristics, and the pixel size of the sensor array. More detailed images are possible with higher spatial resolution (smaller pixel sizes), which highlights smaller features in the observed region.\nSpatial resolution (geometric) o Low resolution &gt;= 30m &lt; 300m o Medium resolution &gt;= 5 &lt; 30m o High resolution &gt;= 2m &lt; 5m o Very high resolution &lt; 2m\nFor example:\nThe Landsat 8 OLI sensor shows improved spectral resolution, indicated by the increased number of bands and narrower bandwidths (compared to Landsat 4-5 (MSS)). This improvement allows for more precise detection of different features on the Earth’s surface due to the ability to capture more specific ranges of the spectrum and differentiate between more subtle differences in reflectance.\no Panchromatic (wide bandwidth, visible range of spectrum) o Multispectral &gt;= 3 spectral bands (RGB, RGB NIR + MIR) o Hyperspectral &gt;= 30 spectral bands (lower geometric and resolution) o These images have high spectral resolution but low spatial resolution\n(Higher number of bits = higher the radiometric resolution = higher the quality of the image = higher possibility to differentiate features)\nFor example:\n8 bit = 256 possible values; 1 bit = 2 possible values\nImages above clearly illustrute that the 8-bit image has better quality than the 1-bit one.\n4)Temporal: Involves how frequently a sensor collects data of the same area. (Short revisit/reacquisition cycle = better temporal resolution)\nFor example: The satellite orbit above the UK and it won’t come back until the day after 15 days. So if the cycle is shorten to 3 days it’s better temporal resolution.\nSo much knowledge! Thank you for your summary and explanation, but I need some time to understand.\ntake your time! Next, I will review the application of remote sensing according to some literature, which will help you understand.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1 - Intro to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "2  Week 2 - Short Presentation",
    "section": "",
    "text": "xaringanExtra::embed_xaringan( url = “https://zhaowei777.github.io/PPT/”, ratio = “16:9”)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 2 - Short Presentation</span>"
    ]
  },
  {
    "objectID": "week1.html#overview",
    "href": "week1.html#overview",
    "title": "1  Week 1 - Intro to Remote Sensing",
    "section": "",
    "text": "Remote sensing\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrequency, Speed and the Wave-length\n\n\n\n\nSpectral: Describes the number and width of spectral bands that a sensor records. (more or narrower bands = better spectral resolution)\n\n\n\n\n\nImproved Spectral Resolution of Landsat 8 Instrument (OLI)\n\n\n\n\n\nRadiometric: defines the ability to resolve objects with similar reflectance (within the same wavelength)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1 - Intro to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "week3.html",
    "href": "week3.html",
    "title": "3  week 3 - corrections",
    "section": "",
    "text": "3.1 Overview\nStarting from this week, I will use the form of mind maps to summarize this week’s knowledge, an intuitive and focused way.\nOK! Now Let’s explore some applications!",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>week 3 - corrections</span>"
    ]
  },
  {
    "objectID": "week3.html#overview",
    "href": "week3.html#overview",
    "title": "3  week 3 - corrections",
    "section": "",
    "text": "Week3 Mind Map",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>week 3 - corrections</span>"
    ]
  },
  {
    "objectID": "week1.html#applications",
    "href": "week1.html#applications",
    "title": "1  Week 1 - Intro to Remote Sensing",
    "section": "1.2 Applications",
    "text": "1.2 Applications\n\n\n“In science there is only physics; all the rest is stamp collecting.”\n\n\n                                                    —————William Thomson(Lord Kelvin)\n\n\nThe fundamental core of remote sensing technology is electromagnetism, the interactions of electromagnetic energy with the atmosphere and the Earth’s surface are critical in determining the quality and type of data collected. The electromagnetic spectrum highlights the diverse range of electromagnetic waves, from long radio waves to short gamma rays, and the human eye’s ability to detect only a small portion of this spectrum, known as visible light. \nPresented below are several prevalent electromagnetic waves utilized in the field of remote sensing, along with their respective applications and examples of corresponding remote sensing satellites.\n\nVisible Light and Near-Infrared: These bands are commonly used for monitoring land cover, vegetation health, urban planning, and environmental changes. Vegetation is strongly reflected in these bands, making it possible to assess the health and density of vegetation. Satellite Examples: Landsat Series: For global environmental monitoring, including agriculture, and forest coverage. Sentinel-2: Providing high-resolution images of land cover and vegetation health.\nThermal Infrared: Used for measuring surface temperature, fire detection, evapotranspiration, and sea surface temperature monitoring. Thermal infrared data can help analyze drought conditions and the urban heat island effect. Satellite Examples: MODIS: Onboard the Terra and Aqua satellites, providing global climate system observations, including surface temperature.\nMicrowave: As microwaves can penetrate clouds, dust, smoke, snow, and rain, they are ideal for satellite communication in extreme weather conditions. Microwave remote sensing is crucial for understanding global water cycles and climate change. Satellite Examples: SMAP (Soil Moisture Active Passive): A NASA satellite focused on global soil moisture measurement to help forecast floods and droughts. GRACE (Gravity Recovery and Climate Experiment) Series: To measure variations in Earth’s gravitational field and deduce changes in ice mass and groundwater storage.\nUltraviolet: Mainly used for atmospheric and solar studies, including ozone layer monitoring, solar activity observation, and air quality assessment. Satellite Examples: Aura Satellite: Carrying the OMI (Ozone Monitoring Instrument) focused on atmospheric composition and atmospheric chemistry studies.\nX-Rays and Gamma Rays: Mainly employed in the field of astronomy to investigate high-energy events in the universe, such as black holes, neutron stars, and remnants of supernovas. Satellite Examples: Chandra X-ray Observatory: For studying high-temperature objects and X-ray sources in the universe.\n\nAs we can see above, with the cornerstone of electromagnetic technology, remote sensing can be utilized across interdisciplinary fields, especially contributing significant power to urban-related studies. For urban environments, the differentiation between wavelengths allows for the identification of specific gases in the atmosphere, which can be used to monitor air quality or track the movement of atmospheric pollutants. In terms of Urban Agriculture, it enables the identification of healthy versus stressed vegetation, allowing for precise monitoring of crop health and the optimization of agricultural practices. Within the field of Urban Planning, it provides critical data for urban planning, such as land use classification and urban expansion. As for Urban Climate Studies, remote sensing data contribute to understanding and modelling climate systems and tracking changes in ice cover, sea levels, and global temperatures.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1 - Intro to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "week1.html#reflection",
    "href": "week1.html#reflection",
    "title": "1  Week 1 - Intro to Remote Sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nBased on my interest in the Internet of Things (IoT), I have developed some ideas about the relationship between remote sensing and IoT. In my view, the development of the two disciplines, remote sensing and IoT, is blurring the distance between them. Both technologies are driven by similar needs- to efficiently collect data on a large scale without requiring a lot of manpower. They have both evolved to be able to analyse data and simplify large amounts of data to make it easy to understand.\nBased on what I’ve learnt about remote sensing this week, I believe that remote sensing and the Internet of Things are essentially complementary and that they have different strengths for solving problems. Remote sensing can essentially be thought of as “external IoT”, whereas traditional IoT uses embedded or internal sensors. Combining the two offers even greater potential. For example, sensors inside an underground pipe may detect a drop in pressure at a certain cross-section, but external hyperspectral sensors can link this pressure to changes present in the ground and synthesise the root cause of the problem. The data generated by these technologies has the potential to provide a wide range of new insights, reduce costs and improve system performance.\nWith their combination, plus the utilisation of new technologies such as artificial intelligence and cloud computing. There is an opportunity for a whole host of new ways to protect critical infrastructure, preserve the environment and improve human life.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1 - Intro to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "week6.html",
    "href": "week6.html",
    "title": "5  week 6 - intro to GEE",
    "section": "",
    "text": "5.1 Overview\nI’m currently learning how to use GEE and I found a video to start it as a beginner!\nIn this week’s lecture, we talked about “Loops and Mapping”, can you explain a little bit more?\n“Loops and Mapping” in GEE emphasizes a key distinction in managing repetitive tasks. Loops are frequently used in traditional programming to repeat tasks, however, because GEE uses a server-based data architecture, they are inefficient. Rather, GEE prefers “Mapping,” an approach that effectively applies a function to every element (such as features or images) in a collection. Mapping aligns with GEE’s cloud processing, allowing for parallel, distributed computations over large datasets, making it a preferred method for scalability and performance.\nI see! Then let’s talk about “reducing images”.\nThe action of “reducing images” in GEE entails condensing large image databases into simpler forms. It is possible to employ many techniques in image analysis, such as calculating median values to reduce noise, conducting zonal statistics within certain regions to comprehend changes, or utilizing the reduceRegion function to obtain average values inside a geographical border. It’s essential for extracting meaningful information from complex spatial data efficiently.\nLast question- Linear regression in GEE?\nGEE uses linear regression to examine the changes in pixel values over time across satellite images. By integrating a temporal variable into images and using the ee.Reducer function, calculating the slopes and intercepts for each pixel, allows for the identification of trends such as vegetation growth or urban development. This approach offers an in-depth comprehension of environmental changes with accuracy in both time and space(Google Earth Engine, 2023).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>week 6 - intro to GEE</span>"
    ]
  },
  {
    "objectID": "week3.html#applications",
    "href": "week3.html#applications",
    "title": "3  week 3 - corrections",
    "section": "3.2 Applications",
    "text": "3.2 Applications\nVegetation Indices (VIs) have evolved over the past four decades in the field of remote sensing, becoming essential tools for assessing vegetation. Since the launch of the first Earth Resource Satellite in 1972, scientists have been attempting to establish approximate relationships between spectral responses and vegetation cover(Eastman et al., 2013).\nOver the past two decades, more than forty vegetation indices have been researched and developed, such as the Normalized Difference Vegetation Index (NDVI), Enhanced Vegetation Index (EVI), and Soil-Adjusted Vegetation Index (SAVI).\n\n\n\nEnhanced Vegetation Index World-wide 2011\n\n\nWhile VIs provide a convenient and quick tool for vegetation monitoring, their application is influenced and constrained by factors such as weather conditions, observational conditions of remote sensors, soil moisture, etc. Moreover, in different environmental conditions, the analysis of vegetation indices becomes more complex(Xue & Su, 2017). This also implies that future research should target the vegetation-soil-atmosphere system as a whole, taking into consideration the characteristics of remote sensors and electromagnetic radiation.\nAdditionally, the effectiveness of using VIs for vegetation monitoring greatly depends on the spatial, spectral, and temporal resolution of remote sensing data. Lower resolutions may not accurately capture small-scale vegetation changes, while acquiring high-resolution data can be costly.\nLooking forward to future developments, with the rapid advancement of artificial intelligence and the repeated mention of smart cities, smart agriculture becomes a crucial part of smart cities, where Vegetation Indices can be fully utilized. Integrating multi-temporal satellite and unmanned aerial vehicle (UAV) observational data with field soil, vegetation, and yield observations, soil type maps, elevation maps, historical parcel and crop information, and meteorological data could provide data support for agricultural management, enabling more precise crop management. Furthermore, the introduction of concepts like “Task Map 2.0” and “AgroGIS,” which automatically generate precise crop management instructions, further promotes the practice of ‘Smart Agriculture’(Nicholas et al., 2022).\nHere is an example- Applications of Remote Sensing in Precision Farming:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>week 3 - corrections</span>"
    ]
  },
  {
    "objectID": "week3.html#reflection",
    "href": "week3.html#reflection",
    "title": "3  week 3 - corrections",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\nDue to my interest in the Internet of Things (IoT), in my past explorations I have seen the great potential of IoT and its application to smart agriculture. Through this week’s study, I have realised that remote sensing can also contribute immensely to smart agriculture, and that this interdisciplinary development is an inevitable trend in the development of our present society, and an important way in which we can contribute to the achievement of the goals of the United Nations.\nThere is a remarkable example in practical applications: In Wageningen, Nederland, The National Smart Farming Pilot Project (NPPL) has been established by the Ministry of Agriculture, Nature and Food Quality and Wageningen Plant Research ProAgrica, it aims to combine remote sensing technology and Internet of Things technology to create more productive and intelligent agricultural systems(Wageningen University & Research, 2017).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>week 3 - corrections</span>"
    ]
  },
  {
    "objectID": "week3.html#references",
    "href": "week3.html#references",
    "title": "3  week 3 - corrections",
    "section": "3.4 References",
    "text": "3.4 References\nEastman, J.R., Sangermano, F., Machado, E.A., Rogan, J. and Anyamba, A., 2013. Global trends in seasonality of normalized difference vegetation index (NDVI), 1982–2011. Remote Sens., 5(10), pp.4799-4818. Available at: https://doi.org/10.3390/rs5104799 [Accessed 28 January 2024].\nJensen, J.R., 2015. Introductory Digital Image Processing: A Remote Sensing Perspective. Prentice-Hall Inc., pp.208-273.\nXue, J. and Su, B., 2017. Significant remote sensing vegetation indices: A review of developments and applications. Volume 2017, Article ID 1353691. Available at: https://doi.org/10.1155/2017/1353691 [Accessed 28 January 2024].\nNicholas, N.J.H., Ng, Y.P. and Tew, Y., 2022. Intelligent farming with NDVI integrated agriculture solution. In: 2022 International Conference on Green Energy, Computing and Sustainable Technology (GECOST), Miri Sarawak, Malaysia. IEEE, pp. 342-345. Available at: doi:10.1109/GECOST55694.2022.10010427 [Accessed 28 January 2024].\nSchulte to Bühne, H. and Pettorelli, N., 2018. Better together: Integrating and fusing multispectral and radar satellite imagery to inform biodiversity monitoring, ecological research and conservation science. Methods in Ecology and Evolution, 9, pp.849-865.\nWageningen University & Research, 2017. National Smart Farming pilot project. Available at: https://www.wur.nl/en/project/national-smart-farming-pilot-project.htm [Accessed 28 January 2024].",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>week 3 - corrections</span>"
    ]
  },
  {
    "objectID": "week4.html",
    "href": "week4.html",
    "title": "4  week 4 - policy",
    "section": "",
    "text": "4.1 Overview - Assessing Burn Scars After Bushfire in Sydney\nDo you remember the 2019–20 bushfires in Sydney? You and I were both in Melbourne at the time, and we were also affected\nI do. It was a tragedy. Those people, animals, and plants that lost their lives in that fire- R.I.P.. Today, let’s explore the application of remote sensing technology in assessing burn scars after bushfire, in conjunction with relevant policies.\nIn today’s world, remote sensing technology has become an important tool for detecting and managing urban challenges, building a bridge between scientific research and policy development.\nBush Fire is one of the most commonly occurring natural disasters in Australia which brings huge damage to the land and requires a relatively long recovery period. Sydney, surrounded by vast tracts of bushland, is inherently vulnerable to the threat of bushfires, which have become more frequent and intense due to climate change and urban encroachment into forested areas. However, considering the scale of the bushfire and human ability, it is hard to examine the post-fire condition manually. Hence Landsat satellites are constantly being used to capture and analyze spatial information on large scales, such as detecting physically affected regions after fire, predicting the potential hazards, generate vegetation regrowth.\nThe significance of post-wildfire assessments in Australia, particularly regarding the evaluation of burn scars, is underscored by the “National Bushfire Management Policy Statement for Forests and Rangelands” (2014). “Planning for Bush Fire Protection 2019” further complements this approach by providing detailed guidelines for post-bushfire planning.\nBy assessing the burn scars left by bushfires, we can gain a better understanding of the environmental impact of fires and provide critical information for rebuilding and restoration efforts, which is significant for achieving the United Nations Sustainable Development Goals.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>week 4 - policy</span>"
    ]
  },
  {
    "objectID": "week4.html#overview---assessing-burn-scars-after-bushfire-in-sydney",
    "href": "week4.html#overview---assessing-burn-scars-after-bushfire-in-sydney",
    "title": "4  week 4 - policy",
    "section": "",
    "text": "Goal 13: Climate Action - Monitoring and assessing the aftermath of fires can improve our understanding of how climate change affects the frequency and intensity of wildfires, leading to better adaptation and mitigation strategies.\nGoal 15: Life on Land - Evaluating the extent of ecosystem damage through burn scar assessments helps in taking appropriate restoration and conservation measures, protecting terrestrial ecosystems and biodiversity.\nGoal 11: Sustainable Cities and Communities - Assessing burn scars is also related to reducing disaster risk and enhancing disaster response capabilities (such as to wildfires), crucial for protecting human settlements and ensuring the sustainability of cities and communities.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>week 4 - policy</span>"
    ]
  },
  {
    "objectID": "week4.html#applications",
    "href": "week4.html#applications",
    "title": "4  week 4 - policy",
    "section": "4.2 Applications",
    "text": "4.2 Applications\nThe importance of accurately assessing burn scars extends beyond ecological concerns; it directly influences post-disaster reconstruction and mitigation strategies. By understanding the severity of wildfires and the specific areas most affected, policymakers and urban planners can prioritize rehabilitation efforts, allocate resources more efficiently, and implement land management practices aimed at reducing the risk of future fires. Furthermore, the integration of fire severity patterns with vegetation type data can improve the accuracy of fire intensity inferences, aiding in the refinement of fire management policies and practices.\nNext, I will practice examining the burn severity and scars of the bushfire that took place in Kosciusko National Park, New South Wales between the end of 2019 and the beginning of 2020 through a range of applications using Landsat 8 datasets. This will be more helpful to your understanding of burn scar evaluation and related policy formulation.\nLast week we talked about NDVI, Today we explore another index. The Burn Area Index (BAI) is an important element for analyzing burn scars, which uses the reflectance values in the red and NIR (Near Infrared) portion of the spectrum to identify the areas of the terrain affected by fire(Mashhadi & Alganci, 2021).\n\n\n\nPre-fire BAI(lest) VS. Post-fire BAI(right)\n\n\nIn above images, the white pixels indicate the area that has been burned, while the darker pixels indicate the presence of healthy vegetation.\nFor other visualization, Normalized Burn Ratio Images show below:\n\n\n\nPre-fire NBR(lest) VS. Post-fire NBR(right)\n\n\nNBR is determined by utilizing wavelengths in the near infrared and shortwave infrared spectrum. The presence of a burnt area is indicated by a higher nominalized burn ratio, as burnt vegetation exhibits a lower near infrared reflectance and a higher shortwave infrared wavelength. In contrast, healthy vegetation displays the opposite characteristics. Therefore, the darker region with a low NBR value indicates the burnt area.\nNext, By utilizing the Float(b2-b1) function, where b2 represents the NBR image before the fire and b1 represents the NBR image after the fire, I calculated the difference between the pre and post fire NBR images. The image highlights burnt areas, which are represented by white pixels. The severity of burn scars is indicated by the higher clarity and brightness of the white pixels.\n\n\n\nDifferenced Normalized Burn Ratio Image\n\n\nFinally, I created a burn severity map. Using the U.S. Geological Survey’s FIREMON program’s burn severity categories as a guide, creating seven levels of severity in order to visually represent them.\n\n\n\nMap of Fire Severity\n\n\nBased on the map above, it provides better visualisation to assess the burn scars, relevant policymakers such as the NSW Government and the Department of Planning and Environment can more accurately deploy post-disaster policies. Potential policies may be as follows:\n\nReconstruction and Recovery Policy: Based on the severity maps of forest burn scars, the government can develop specific forest restoration plans, including reforestation and ecosystem rebuilding, to facilitate the natural recovery of damaged areas.\nPrevention and Disaster Mitigation Policy: Utilizing burn scar severity maps to identify high-risk areas, the government can implement preventive measures in these areas, such as establishing firebreaks and enhancing monitoring and early warning system capabilities.\nLand Use and Planning Policy: Based on the distribution and severity of burned areas, land use planning can be adjusted to limit development in high-risk areas and protect areas of flammable vegetation from being disturbed.\nFunding Allocation and Resource Distribution Policy: Resources and funding should be prioritized for areas most severely affected by burns, as indicated by the burn scar severity maps, to support emergency response, recovery, and prevention efforts.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>week 4 - policy</span>"
    ]
  },
  {
    "objectID": "week4.html#literature-review-and-reflection",
    "href": "week4.html#literature-review-and-reflection",
    "title": "4  week 4 - policy",
    "section": "4.3 Literature Review and Reflection",
    "text": "4.3 Literature Review and Reflection\nThe increasing emphasis on sustainability in all facets of urban development and management has encouraged the use and progress of remote sensing technology in city-related applications. However, the integration among remote sensing, ecology, and urban planning disciplines remains limited, with only 12% of the studies achieving a comprehensive integration of knowledge across these three fields(Wellmann et al., 2020). Most research primarily aims to expand the knowledge base or monitor the impact of existing policies, with few studies directly related to policy, such as providing concrete recommendations or evaluations for planning issues. Therefore, in the future, overcoming information barriers, the necessity of interdisciplinary integration, and enhancing the application of remote sensing knowledge throughout the policy cycle are critical considerations for policymakers and technologists(Kadhim, Mourshed & Bray, 2016).\nMy mini applications serves merely as a conceptual demonstration of assessing wildfire damage using remote sensing data and cannot act as a direct indicator for policy recommendations. In the real world, it is essential to consider a broader range of factors, such as economics, botany, and biology. This reflects the complexity of policy-making, indicating that any tech or Method can only assist in the process- the true wisdom lies in finding a balance among complex, interdisciplinary factors.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>week 4 - policy</span>"
    ]
  },
  {
    "objectID": "week4.html#refences",
    "href": "week4.html#refences",
    "title": "4  week 4 - policy",
    "section": "4.4 Refences",
    "text": "4.4 Refences\nGerasopoulos, E., Bailey, J., Athanasopoulou, E., Speyer, O., Kocman, D., Raudner, A., Tsouni, A., Kontoes, H., Johansson, C., Georgiadis, C., Matthias, V., Kussul, N., Aquilino, M., Paasonen, P., 2022. Earth observation: An integral part of a smart and sustainable city. Environmental Science & Policy, 132, pp.296-307.\nKadhim, N., Mourshed, M. and Bray, M., 2016. Advances in remote sensing applications for urban sustainability. Euro-Mediterranean Journal of Environmental Integration, 1, 7.\nMashhadi, N. and Alganci, U., 2021. Determination of forest burn scar and burn severity from free satellite images: a comparative evaluation of spectral indices and machine learning classifiers. International Journal of Environment and Geoinformatics, 8(4), pp.488-497. Available at: https://doi.org/10.30897/ijegeo.879669 [Accessed 4 February 2024].\nNSW Rural Fire Service, 2019. Planning for Bush Fire Protection: A guide for councils, planners, fire authorities and developers. NSW Rural Fire Service, November. ISBN 978-0-646-99126-9.\nSmith, R., 2016. Firebreak Location, Construction and Maintenance Guidelines. Fire and Emergency Services Authority of Western Australia, Perth. ISBN 978-0-9806116-6-3.\nWellmann, T., Lausch, A., Andersson, E., Knapp, S., Cortinovis, C., Jache, J., Scheuer, S., Kremer, P., Mascarenhas, A., Kraemer, R., Haase, A., Schug, F., Haase, D., 2020. Remote sensing in urban planning: Contributions towards ecologically sound policies? Landscape and Urban Planning, 204, 103921.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>week 4 - policy</span>"
    ]
  },
  {
    "objectID": "week6.html#overview",
    "href": "week6.html#overview",
    "title": "5  week 6 - intro to GEE",
    "section": "",
    "text": "Week6 Mind map",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>week 6 - intro to GEE</span>"
    ]
  },
  {
    "objectID": "week6.html#applications",
    "href": "week6.html#applications",
    "title": "5  week 6 - intro to GEE",
    "section": "5.2 Applications",
    "text": "5.2 Applications\nGoogle Earth Engine makes remote sensing analysis more efficient. Its advantage is that it is a geospatial processing platform based on cloud computing and provides free access to a large amount of satellite data, so it is widely used in various fields. A total of 90 journals published articles on GEE between 2020 and 2022, demonstrating the multidisciplinary applications of the GEE platform - including deforestation, natural disasters, infectious diseases, agriculture, water management, climate monitoring and geological resources(Amani et al., 2020)\n\n\n\nCategorization of GEE applications by discipline.(Tamiminia et al., 2020)\n\n\nEarth Engine is also unique in that it not only serves traditional remote sensing scientists but also targets a broad range of non-technical users. However, even if many users can use the R language, they still need to spend time studying the GEE language, because Google Earth Engine requires JavaScript or Python programming language to write code. Meanwhile, GEE also has some issues related to data privacy(Zhao et al., 2021). The advantages and limitations of GEE are presented in the following table:\n\n\n\nMerits and limitations of GEE and GE.(Zhao et al., 2021)\n\n\nI found a case demonstrates the great potential of GEE technology in the agricultural field. Sydney startup Regrow Ag uses Google Earth Engine (GEE) technology to achieve innovative applications in the agricultural field. By analyzing satellite images to measure agricultural carbon sequestration and improve crop yields, Regrow Ag has attracted big customers like Kellogg’s and successfully raised $50 million in Series B funding(Dalton, 2022).\n\n\n\nAn example of a grower’s dashboard of fields analysed by Regrow Ag.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>week 6 - intro to GEE</span>"
    ]
  },
  {
    "objectID": "week6.html#reflection",
    "href": "week6.html#reflection",
    "title": "5  week 6 - intro to GEE",
    "section": "5.3 Reflection",
    "text": "5.3 Reflection\nGEE has built a shared platform to promote interdisciplinary research. This reminds me that in the Internet of Things, interdisciplinary research is also the core. In today’s era of rapid technological development, independent disciplines should seek multi-faceted cooperation. At the same time, the openness and easy access of GEE have also greatly promoted the development of global education, especially in developing countries with limited resources. This will go a long way to narrowing the digital divide around the world and promoting educational equity.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>week 6 - intro to GEE</span>"
    ]
  },
  {
    "objectID": "week6.html#references",
    "href": "week6.html#references",
    "title": "5  week 6 - intro to GEE",
    "section": "5.4 References",
    "text": "5.4 References\nAmani, M., Ghorbanian, A., Ahmadi, S.A., Kakooei, M., Moghimi, A., Mirmazloumi, S.M., Alizadeh Moghaddam, S.H., Mahdavi, S., Ghahremanloo, M., Parsian, S., Wu, Q. and Brisco, B., 2020. Google Earth Engine Cloud Computing Platform for Remote Sensing Big Data Applications: A Comprehensive Review. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 13, pp.5326-5350. https://doi.org/10.1109/JSTARS.2020.3021052.\nDalton, A., 2022. Sydney start-up Regrow Ag first to harness Google Earth Engine. The Sydney Morning Herald. [online] Available at: https://www.smh.com.au/business/entrepreneurship/sydney-start-up-regrow-ag-first-to-harness-google-earth-engine-20220801-p5b69d.html [Accessed 25 February 2024].\nTamiminia, H., Salehi, B., Mahdianpari, M., Quackenbush, L., Adeli, S. and Brisco, B., 2020. Google Earth Engine for geo-big data applications: A meta-analysis and systematic review. ISPRS Journal of Photogrammetry and Remote Sensing. https://doi.org/10.1016/j.isprsjprs.2020.04.001 [Accessed 25 February 2024].\nZhao, Q., Yu, L., Li, X., Peng, D., Zhang, Y. and Gong, P., 2021. Progress and trends in the application of Google Earth and Google Earth Engine. Remote Sensing, 13(18), 3778. Available at: https://doi.org/10.3390/rs13183778 [Accessed 25 February 2024].",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>week 6 - intro to GEE</span>"
    ]
  },
  {
    "objectID": "week7.html",
    "href": "week7.html",
    "title": "6  week 7 - classification",
    "section": "",
    "text": "6.1 Overview\nIt seems like we get into machine learning with Google Earth Engine this week.\nYes!Let’s explore more!\nCART is a type of predictive algorithm that can be used for both classification and regression, which uses Gini Index criterion to split a node to a sub-node(Breiman et al., 1984).In Google Earth engine, it is included in supervised classification algorithms.\nClassification trees are tree models designed for scenarios where the target variable encompasses a specific set of discrete outcomes, with the branches indicating feature combinations leading to distinct class labels represented by the leaves.\nConversely, regression trees deal with target variables that assume continuous values, usually within the real number range(Studer et al., 2011).\nI also get a summary of this week’s knowledge!\n- Classification serves critical roles in extracting meaningful information from Earth Observation (EO) data for various applications.\n- Both supervised and unsupervised methods have their merits, with the choice of method depending on the specific application and available data.\n- Advanced methods like Random Forests and SVM provide powerful tools for handling complex classification tasks, though they come with considerations regarding model complexity and overfitting.\nAwesome!",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>week 7 - classification</span>"
    ]
  },
  {
    "objectID": "week7.html#overview",
    "href": "week7.html#overview",
    "title": "6  week 7 - classification",
    "section": "",
    "text": "Week7 Mind map\n\n\n\n\n\n\n\n\nFormula of Gini Index",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>week 7 - classification</span>"
    ]
  },
  {
    "objectID": "week7.html#applications",
    "href": "week7.html#applications",
    "title": "6  week 7 - classification",
    "section": "6.2 Applications",
    "text": "6.2 Applications\nFor high-resolution remote sensing images, the spectral features of ground objects become increasingly complex, making phenomena like “same object, different spectra” and “different objects, same spectrum” more pronounced. This complexity leads to a decrease in the accuracy of traditional parametric methods such as Minimum Distance Classification (MDC) and Maximum Likelihood Classification (MLC). Consequently, non-parametric methods like Support Vector Machines (SVM), Artificial Neural Networks (ANN), and Decision Trees (DT) have found widespread application in classifying high-resolution remote sensing images. However, these methods are considered shallow learning algorithms and often struggle to effectively model complex functions or adapt to complex samples. They also face challenges in accurately estimating the parameters of classifier models, leading to unsatisfactory classification results.\nA scientific team conducted an experiment using remote sensing datasets from Helsinki, Finland, titled “CNN-Based Land Cover Classification Combining Stratified Segmentation and Fusion of Point Cloud and Very High-Spatial Resolution Remote Sensing Image Data.” This experiment demonstrates that CNN (Convolutional Neural Network) classification methods can effectively improve the accuracy of remote sensing image classification(Zhou et al., 2019). However, as a novel machine learning approach, CNNs still have many imperfections. These mainly include the complexity and large number of network model parameters, lengthy training times, and a lack of comprehensive theoretical support for network model structure design, necessitating extensive experimentation to identify optimal parameters. Moving forward, the focus of research will shift towards improving model training speed and identifying the best parameters.\n\n\n\nThe workflow for the convolutional neural network (CNN)-based land cover classification method combining stratified segmentation and point cloud data fusion.(Zhou et al., 2019)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>week 7 - classification</span>"
    ]
  },
  {
    "objectID": "week7.html#reflection",
    "href": "week7.html#reflection",
    "title": "6  week 7 - classification",
    "section": "6.3 Reflection",
    "text": "6.3 Reflection\nWhen we explore the potential of convolutional neural networks (CNN), we should not be limited to the classification of remote sensing images. The application scope of CNN goes far beyond the boundaries of a single field, and the types of images it can process and analyze are also very wide. For example, in urban street monitoring, CNN can be used to monitor changes in urban layout, traffic flow, and even public safety events. This technology can not only improve the efficiency of urban management, but also respond to emergencies in real time and improve the quality of life of urban residents.\nBy combining CNN in street monitoring and remote sensing data, we can achieve more comprehensive and dynamic urban management. Remote sensing technology can monitor urban development, environmental changes and natural resource utilization from a macro perspective, while street-level monitoring provides a microscopic perspective, capturing the details of a city’s daily operations. The combination of the two allows urban planners and managers to more accurately understand the development dynamics of the city and make more reasonable decisions.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>week 7 - classification</span>"
    ]
  },
  {
    "objectID": "week7.html#references",
    "href": "week7.html#references",
    "title": "6  week 7 - classification",
    "section": "6.4 References",
    "text": "6.4 References\nBreiman, L., Friedman, J.H., Olshen, R.A. and Stone, C.J., 1984. Classification and Regression Trees. Monterey, CA: Wadsworth & Brooks/Cole Advanced Books & Software. ISBN 978-0-412-04841-8.[Accessed 5 March 2024]\nPal, M. & Mather, P.M., 2005. Support vector machines for classification in remote sensing. International Journal of Remote Sensing, 26(5), pp.1007-1011. https://doi.org/10.1080/01431160512331314083.[Accessed 5 March 2024]\nStuder, M., Ritschard, G., Gabadinho, A. and Müller, N.S., 2011. Discrepancy Analysis of State Sequences. Sociological Methods & Research, 40(3), pp.471-510. https://doi.org/10.1177/0049124111415372.[Accessed 7 March 2024]\nYang, C.-C., Prasher, S.O., Enright, P., Madramootoo, C., Burgess, M., Goel, P.K. and Callum, I., 2003. Application of decision tree technology for image classification using remote sensing data. Agricultural Systems, 76(3), pp.1101-1117. https://doi.org/10.1016/S0308-521X(02)00051-3.[Accessed 5 March 2024]\nZhou, K., Ming, D., Lv, X., Fang, J. and Wang, M., 2019. CNN-based land cover classification combining stratified segmentation and fusion of point cloud and very high-spatial resolution remote sensing image data. Remote Sensing, 11(17), 2065. https://doi.org/10.3390/rs11172065.[Accessed 5 March 2024]",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>week 7 - classification</span>"
    ]
  },
  {
    "objectID": "week9.html",
    "href": "week9.html",
    "title": "8  week 9 - SAR",
    "section": "",
    "text": "8.1 Overview\nIn this lecture we explore SAR in more detail than in all previous lectures. Let’s take a deeper look at its application in the following section!\nHere I found a very good video about SAR by Scott Manley:",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>week 9 - SAR</span>"
    ]
  },
  {
    "objectID": "week9.html#overview",
    "href": "week9.html#overview",
    "title": "8  week 9 - SAR",
    "section": "",
    "text": "Week9 Mind map",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>week 9 - SAR</span>"
    ]
  },
  {
    "objectID": "week9.html#applications",
    "href": "week9.html#applications",
    "title": "8  week 9 - SAR",
    "section": "8.2 Applications",
    "text": "8.2 Applications\nThis week I discussed the possible advantages and disadvantages of SAR imagery.\nSAR satellite imagery boasts several advantages, making it an invaluable tool for earth observation under various conditions. One of its most significant benefits is its capability to acquire data anytime, regardless of daylight, as it is not limited by light conditions and can operate both day and night without the need for sunlight. Furthermore, its all-weather capability is another substantial advantage; the radio frequency radiation it uses is not significantly affected by clouds, precipitation, or other atmospheric conditions, allowing it to work under any weather circumstances. SAR imagery’s resolution is independent of the flight altitude, offering more flexibility in satellite orbit selection. Unlike visible light and infrared imaging, SAR can penetrate deeper into vegetation and soil, depending on the microwave wavelength, offering possibilities for inverting surface vegetation and soil characteristics. It can also collect data in different wavelengths and polarizations to derive various types of information, such as surface structure and moisture content, across large areas at lower resolution or in detailed high resolution for smaller zones.\nHowever, SAR imagery also comes with its set of drawbacks. Certain nonlinear frequency-modulated continuous-wave (FMCW) signals in SAR images have a lower signal-to-noise ratio. The side-looking coherent imaging mode it utilizes can lead to severe image noise pollution. SAR systems are complex by design, handling large volumes of data, making it challenging to extract effective feature information. Compared to optical remote sensing images, SAR data typically have lower spatial resolution and less visually appealing results. The complexity of SAR imaging technology and data post-processing can pose significant difficulties, requiring technicians to undergo long training periods and possess a solid foundation in physics. Moreover, in the application field of interferometric deformation recognition, the effectiveness in mountainous areas is compromised due to significant deformation gradients.\nIn summary, while SAR satellite imagery offers unparalleled advantages in its all-time and all-weather capabilities, deep penetration, and flexibility in information gathering, its application is hindered by challenges related to image noise, system complexity, lower spatial resolution compared to optical imagery, and technical barriers in data processing and deformation recognition.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>week 9 - SAR</span>"
    ]
  },
  {
    "objectID": "week9.html#reflection",
    "href": "week9.html#reflection",
    "title": "8  week 9 - SAR",
    "section": "8.3 Reflection",
    "text": "8.3 Reflection\nCompleting this remote sensing course has profoundly expanded my understanding and skills in utilizing Earth observation data for environmental hazard mitigation, especially within urban sustainability contexts. Through hands-on practice in R and exploring advanced methodologies, I’ve learned to pre-process imagery, extract meaningful insights from spatial data, and apply these insights to optimize climate mitigation strategies. This experience has not only sharpened my technical abilities but also heightened my awareness of the critical importance of spatial data in shaping effective urban and environmental policies. Armed with this knowledge, I feel prepared to contribute to data-driven solutions for a sustainable future. I’m deeply grateful for this enriching learning journey and the invaluable insights it has provided.:)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>week 9 - SAR</span>"
    ]
  },
  {
    "objectID": "week9.html#references",
    "href": "week9.html#references",
    "title": "8  week 9 - SAR",
    "section": "8.4 References",
    "text": "8.4 References\nJao, J.K., 2001. Theory of synthetic aperture radar imaging of a moving target. IEEE Transactions on Geoscience and Remote Sensing, 39(9), pp.1984-1992. https://doi.org/10.1109/36.951089.\nOuchi, K., 2013. Recent Trend and Advance of Synthetic Aperture Radar with Selected Topics. Remote Sensing, 5(2), pp.716-807. https://doi.org/10.3390/rs5020716.\nSchulte to Bühne, H. and Pettorelli, N., 2018. Better together: Integrating and fusing multispectral and radar satellite imagery to inform biodiversity monitoring, ecological research and conservation science. Methods in Ecology and Evolution, 9, pp.849-865. Available at: https://doi.org/10.1111/2041-210X.1294.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>week 9 - SAR</span>"
    ]
  },
  {
    "objectID": "week1.html#references",
    "href": "week1.html#references",
    "title": "1  Week 1 - Intro to Remote Sensing",
    "section": "1.4 References",
    "text": "1.4 References\nMilne, Anthony Kinnaird. 1986. “The Use of Remote Sensing in Mapping and Monitoring Vegetational Change Associated with Bushfire Events in Eastern Australia.” Geocarto International 1 (1): 25–32.\nNavalgund, R.R., Jayaraman, V. and Roy, P.S., 2007. Remote sensing applications: An overview. Current Science, 93(12), pp.1747-1766. Available at: http://www.jstor.org/stable/24102069.\nVan Westen, CJ. 2000. “Remote Sensing for Natural Disaster Management.” International Archives of Photogrammetry and Remote Sensing 33 (B7/4; PART 7): 1609–17.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1 - Intro to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "week8.html",
    "href": "week8.html",
    "title": "7  week 8 - classification 2",
    "section": "",
    "text": "7.1 Overview\nThis week, I found accuracy assessment is really important in remote sensing, isn’t it?\nIndeed, determining the accuracy of information from remotely sensed data is essential for ensuring its trustworthiness. This can be done through either qualitative or quantitative approaches. Qualitative assessments quickly eye-check the data or maps to see if they make sense with what’s actually on the ground. Meanwhile, quantitative assessments dive deeper, pinpointing and measuring mistakes by comparing the data on the maps to actual, on-the-ground reference data. The value of ensuring accuracy in remote sensing cannot be overstated; such data plays a pivotal role in mapping and crafting environmental models that guide management decisions and policy-making.\nA quiz for you- In the lecture we also talked about sub-pixel analysis, can you summarize something?\nIn general, Sub-pixel analysis overcomes the limitations of conventional pixel-based classification by providing increased detail in land cover mapping and monitoring. This is crucial for ensuring precise environmental evaluations and enabling well-informed choices regarding land management and conservation.\nFair enough, Let’s explore some relative literature and applications.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>week 8 - classification 2</span>"
    ]
  },
  {
    "objectID": "week8.html#overview",
    "href": "week8.html#overview",
    "title": "7  week 8 - classification 2",
    "section": "",
    "text": "Week8 Mind map",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>week 8 - classification 2</span>"
    ]
  },
  {
    "objectID": "week8.html#application",
    "href": "week8.html#application",
    "title": "7  week 8 - classification 2",
    "section": "7.2 Application",
    "text": "7.2 Application\nThis week I read a wide range of literature and tried to analyze the development, current challenges and future development directions of remote sensing data classification. (Due to the large number of terminologies, I translated some documents into my mother tongue for reading. There may be errors in professional terms during the expression process, but I will try to improve.)\nIn the early stages, classification methods based on manually designed features provided solutions for the classification of remote sensing images. Subsequently, machine learning, built on the foundation of probability, statistics, and other theories, further improved classification accuracy. The advent of deep learning eliminated the reliance on human experts to design features entirely and led to a qualitative leap in classification accuracy. However, challenges in visualizing and interpreting deep network models and the lack of datasets have restrained further improvements in classification accuracy. In the future, the structures and parameters of deep learning networks will be determined more rapidly and accurately. In practical applications, the depth and width of deep learning systems significantly impact classification performance. Deeper and wider networks can uncover more abstract feature representations in the data, enhancing classification effectiveness. However, excessively large network models increase training consumption, reduce training efficiency, and may decrease the network’s generalizability, leading to overfitting. Balancing classification performance with the effective reduction of network complexity is one of the current research hotspots. With technological advancement, data from various types are growing massively. It is worth considering the integration of multisource heterogeneous data, such as from multiple types of sensors, smart devices, and social networking sites, for remote sensing image classification. Multisource heterogeneous data can provide target image features and information from different aspects. The fusion of different features and information not only retains the effective discriminatory information of the features involved but also reduces the uncertainty of single-source data to some extent, making the classification results more reliable and the outcomes of remote sensing image target classification more comprehensive and accurate.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>week 8 - classification 2</span>"
    ]
  },
  {
    "objectID": "week8.html#reflection",
    "href": "week8.html#reflection",
    "title": "7  week 8 - classification 2",
    "section": "7.3 Reflection",
    "text": "7.3 Reflection\nThrough the previous weeks of study, I felt the close connection between this course and CASA0006: Data Science for Spatial Systems and last semester’s CASA0005: Geographic Information Systems and Science. Words like machine learning and deep learning were repeatedly mentioned and applied in this course, which made me think about the combination of remote sensing technology/space science and artificial intelligence, such as GeoAI, which is changing the way we observe the earth. This combination allows us to analyze changes on Earth and in space more quickly and accurately.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>week 8 - classification 2</span>"
    ]
  },
  {
    "objectID": "week8.html#references",
    "href": "week8.html#references",
    "title": "7  week 8 - classification 2",
    "section": "7.4 References",
    "text": "7.4 References\nBarsi, Á., Kugler, Zs., László, I., Szabó, Gy. and Abdulmutalib, H.M., 2018. Accuracy Dimensions in Remote Sensing. The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, Volume XLII-3, pp. [page range if available]. ISPRS TC III Mid-term Symposium “Developments, Technologies and Applications in Remote Sensing”, 7–10 May, Beijing, China.[Accessed 13 March 2024]\nBruzzone, L. and Demir, B., 2014. A Review of Modern Approaches to Classification of Remote Sensing Data. In: I. Manakos and M. Braun, eds. Land Use and Land Cover Mapping in Europe. Remote Sensing and Digital Image Processing, vol 18. Springer, Dordrecht. https://doi.org/10.1007/978-94-007-7969-3_9.[Accessed 13 March 2024]\nCherrill, A., 1994. A comparison of three landscape classifications and investigation of the potential for using remotely sensed land cover data for landscape classification. Journal of Rural Studies, 10(3), pp.275-289. https://doi.org/10.1016/0743-0167(94)90054-X.[Accessed 12 March 2024]\nFoody, G.M., 2004. Sub-Pixel Methods in Remote Sensing. In: Jong, S.M.D. and Meer, F.D.V. eds. Remote Sensing Image Analysis: Including The Spatial Domain. Remote Sensing and Digital Image Processing, vol 5. Springer, Dordrecht. https://doi.org/10.1007/978-1-4020-2560-0_3.[Accessed 12 March 2024]\nGómez-Chova, L., Tuia, D., Moser, G. and Camps-Valls, G., 2015. Multimodal Classification of Remote Sensing Images: A Review and Future Directions. Proceedings of the IEEE, 103(9), https://doi.org/10.1109/JPROC.2015.2464219.[Accessed 12 March 2024]\nMatarira, D., Mutanga, O., Naidu, M. and Vizzari, M., 2023. Object-Based Informal Settlement Mapping in Google Earth Engine Using the Integration of Sentinel-1, Sentinel-2, and PlanetScope Satellite Data. Land, 12(1), 99. https://doi.org/10.3390/land12010099.[Accessed 15 March 2024]\nPal, M. & Mather, P.M., 2005. Support vector machines for classification in remote sensing. International Journal of Remote Sensing, 26(5), pp.1007-1011. https://doi.org/10.1080/01431160512331314083.[Accessed 15 March 2024]",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>week 8 - classification 2</span>"
    ]
  },
  {
    "objectID": "index.html#acknowledgement",
    "href": "index.html#acknowledgement",
    "title": "CASA0023 Learning Diary",
    "section": "Acknowledgement",
    "text": "Acknowledgement\nI extend my sincerest thanks to Dr. Maclachlan and Dr. Ballinger for their invaluable guidance, to our PGTAs for their unwavering support, and to my fellow group members of the FloraDemeter Visionaries.",
    "crumbs": [
      "About Me"
    ]
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "CASA0023 Learning Diary",
    "section": "Introduction",
    "text": "Introduction\nHello! I’m Zhaowei, a student deeply passionate about art, computer science, and urban science, and an enthusiast of music and photography. I am currently pursuing a master’s degree at The Bartlett Centre for Advanced Spatial Analysis, University College London. Throughout my early education, I focused on honing my creative design and oil painting skills, dreaming of becoming an artist. I completed my Bachelor of Design at the University of Melbourne, where I also took foundational courses in artificial intelligence. During that time, I developed a basic understanding of urban planning, spatial engineering, and architecture, and realized the importance of computer science in everyday life and academia.\nThese are some works from my personal photography studio:\n\n\n\nRemote sensing, akin to an aerial photographer, captures the cities from the heavens above\n\n\nMy current research interests lie in the Internet of Things (IoT) and smart cities. I believe that improving people’s quality of life through data science and computer science is a fascinating endeavor. Remote sensing technology significantly advances urban planning by offering detailed insights into land use and environmental changes, enabling sustainable development and improved resilience against environmental challenges.\nIn daily life, there have always been ‘two’ mes: one who loves art and the other who loves computer science. This diary was jointly completed by these ‘two’ mes. The part of me that loves art (in blue font) converses with the part that loves computer science (in black font) during the writing of this diary. The dialogue between these two sides of me together completes this diary.\nThis website serves as my learning diary for the CASA0027 course, reflecting on and deepening my understanding of remote sensing knowledge. I hope everyone enjoys it and I welcome any criticism or praise!\n\n\n“We can really say that we have achieved a level of remote sensing and Earth observation that we have never had before. We’re in the golden age right now with these satellites.”\n\n\n                                                    —————Tim Newman, USGS National Land Imaging Program coordinator",
    "crumbs": [
      "About Me"
    ]
  }
]