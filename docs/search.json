[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Learning Diary",
    "section": "",
    "text": "About Me\nHello! I’m Zhaowei, a student deeply passionate about art, computer science, and urban science, and an enthusiast of music and photography. I am currently pursuing a master’s degree at The Bartlett Centre for Advanced Spatial Analysis, University College London. Throughout my early education, I focused on honing my creative design and oil painting skills, dreaming of becoming an artist. I completed my Bachelor of Design at the University of Melbourne, where I also took foundational courses in artificial intelligence. During that time, I developed a basic understanding of urban planning, spatial engineering, and architecture, and realized the importance of computer science in everyday life and academia.\nThese are some works from my personal photography studio:\n\n\n\nRemote sensing, akin to an aerial photographer, captures the cities from the heavens above\n\n\nMy current research interests lie in the Internet of Things (IoT) and smart cities. I believe that improving people’s quality of life through data science and computer science is a fascinating endeavor. Remote sensing technology significantly advances urban planning by offering detailed insights into land use and environmental changes, enabling sustainable development and improved resilience against environmental challenges. This website serves as my learning diary for the CASA0027 course, reflecting on and deepening my understanding of remote sensing knowledge. I hope everyone enjoys it and I welcome any criticism or praise!\n\n\n“We can really say that we have achieved a level of remote sensing and Earth observation that we have never had before. We’re in the golden age right now with these satellites.”\n\n\n                                                    —————Tim Newman, USGS National Land Imaging Program coordinator",
    "crumbs": [
      "About Me"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Week 1 - Intro to Remote Sensing",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1 - Intro to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Week 2 - Short Presentation",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 2 - Short Presentation</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "week1.html",
    "href": "week1.html",
    "title": "1  Week 1 - Intro to Remote Sensing",
    "section": "",
    "text": "1.1 Overview\nWeek1, let’s start with a ‘simple’ question: What is remote sensing?\nNASA defined Remote sensing as an acquisition of information from a distance. In my understanding, this tech involves acquiring data about entities or regions without direct physical interaction. Typically, it is achieved by detecting and documenting energy that is either reflected or emitted, followed by the processing, analysis, and utilization of this data.\nIts implementation is through sensors mounted on various platforms: like Satellites, Airplanes (for aerial imagery), Drones and Smartphones. There are over 150 satellites in orbit equipped with sensors for remote sensing.\nOh,I see,easy one. What types of sensors are there?\nThere are mainly two types of sensors:\nActive sensors are equipped with their own illumination source, actively emitting electromagnetic waves and then measuring the backscatter that returns to the sensor. Examples like: Radar and LiDAR. Their application includes generating precise digital elevation models through the Shuttle Radar Topography Mission (SRTM), monitoring rainforest depletion via LiDAR technology, and supporting security measures with its effectiveness in marine and Arctic surveillance.\nConversely, passive sensors don’t emit anything. They rely on natural light, detecting reflected energy (in electromagnetic waves) from the sun. Examples like: Landsat series and IRS-series. The Landsat series, active for over four decades, stands as the most enduring Earth observation initiative in passive remote sensing. It provides critical insights into Earth’s climate, ecosystems, and land use changes, serving as a historical marker for environmental transformation.\nEmm, can you provide me with an example respectively makes it easy to understand?\nSure. Active sensors- your iPhone camera with the flash turned on. Passive sensor- your iPhone camera without the flash turned on OR- your eyes.\nGotcha! Next, we move to ‘Electromagnetic waves’. This reminds me of the old days when I was studying A-level physics. Time flies by, it makes me cry :( .\nAs we know most remote sensing relies on detecting and analyzing electromagnetic radiation(EMR) to gather information about objects or areas from afar without direct contact. (We are not focused on some types of remote sensing that use mechanical waves instead of electromagnetic waves like seismographs). Electromagnetic Radiation 1) consists of waves with both electric and magnetic fields that propagate through space, and 2) the electric and magnetic fields are perpendicular to each other.\nThe fundamental Formula related to EMR is:  Electromagnetic radiation (EMR) undergoes several variations before reaching a sensor, rather than being directly reflected. For example: Surface- Energy is absorbed by the surface, and Atmospheric- Energy is scattered by particles in the atmosphere, influencing the clarity and quality of the sensed data.\nThere are Three types of scattering - Rayleigh scattering occurs with particles much smaller than the wavelength of the radiation (like oxygen molecules). This phenomenon explains why the sky appears “blue” during the day and why the sea normally appears “blue”. - Mie scattering happens with particles about the same size as the wavelength (like smoke and dust). - Non-selective scattering involves particles much larger than the wavelength(like water vapour).\nBTW, 1) the moon has a black sky because there is no atmosphere- no scattering can happen. 2) The ocean usually appears blue because it absorbs blue wavelengths the least, scattering and reflecting them to the observer’s eye. 3) Active sensors like Synthetic Aperture Radar (SAR) can pass through clouds.\nCan you explain about Remotely sensed data and the four resolutions?\nOf course, I will explain to you in detail:\nRaster data is typically obtained through remote sensing; however, this varies depending on the sensor.\n4 types of resolution\n1)Spatial resolution: defines the ability to resolve spatially close objects and to identify small objects, which is expressed by Ground Sampling Distance (pixel size on the ground). The GSD is influenced by factors such as the altitude of the sensor, the sensor’s optical characteristics, and the pixel size of the sensor array. More detailed images are possible with higher spatial resolution (smaller pixel sizes), which highlights smaller features in the observed region.\nSpatial resolution (geometric) o Low resolution &gt;= 30m &lt; 300m o Medium resolution &gt;= 5 &lt; 30m o High resolution &gt;= 2m &lt; 5m o Very high resolution &lt; 2m\nFor example:\nThe Landsat 8 OLI sensor shows improved spectral resolution, indicated by the increased number of bands and narrower bandwidths (compared to Landsat 4-5 (MSS)). This improvement allows for more precise detection of different features on the Earth’s surface due to the ability to capture more specific ranges of the spectrum and differentiate between more subtle differences in reflectance.\no Panchromatic (wide bandwidth, visible range of spectrum) o Multispectral &gt;= 3 spectral bands (RGB, RGB NIR + MIR) o Hyperspectral &gt;= 30 spectral bands (lower geometric and resolution) o These images have high spectral resolution but low spatial resolution\n(Higher number of bits = higher the radiometric resolution = higher the quality of the image = higher possibility to differentiate features)\nFor example:\n8 bit = 256 possible values; 1 bit = 2 possible values\nImages above clearly illustrute that the 8-bit image has better quality than the 1-bit one.\n4)Temporal: Involves how frequently a sensor collects data of the same area. (Short revisit/reacquisition cycle = better temporal resolution)\nFor example: The satellite orbit above the UK and it won’t come back until the day after 15 days. So if the cycle is shorten to 3 days it’s better temporal resolution.\nSo much knowledge! Thank you for your summary and explanation, but I need some time to understand.\ntake your time! Next, I will review the application of remote sensing according to some literature, which will help you understand.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1 - Intro to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "2  Week 2 - Short Presentation",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 2 - Short Presentation</span>"
    ]
  },
  {
    "objectID": "week1.html#overview",
    "href": "week1.html#overview",
    "title": "1  Week 1 - Intro to Remote Sensing",
    "section": "",
    "text": "Frequency, Speed and the Wave-length\n\n\n\n\nSpectral: Describes the number and width of spectral bands that a sensor records. (more or narrower bands = better spectral resolution)\n\n\n\n\n\nImproved Spectral Resolution of Landsat 8 Instrument (OLI)\n\n\n\n\n\nRadiometric: defines the ability to resolve objects with similar reflectance (within the same wavelength)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1 - Intro to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "week3.html",
    "href": "week3.html",
    "title": "3  week 3 - corrections",
    "section": "",
    "text": "3.1 Overview\nStarting from this week, I will use the form of mind maps to summarize this week’s knowledge, an intuitive and focused way.\nOK! Now Let’s explore some applications!",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>week 3 - corrections</span>"
    ]
  },
  {
    "objectID": "week3.html#overview",
    "href": "week3.html#overview",
    "title": "3  week 3 - corrections",
    "section": "",
    "text": "Week3 Mind Map",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>week 3 - corrections</span>"
    ]
  },
  {
    "objectID": "week1.html#applications",
    "href": "week1.html#applications",
    "title": "1  Week 1 - Intro to Remote Sensing",
    "section": "1.2 Applications",
    "text": "1.2 Applications\n\n\n“In science there is only physics; all the rest is stamp collecting.”\n\n\n                                                    —————William Thomson(Lord Kelvin)\n\n\nThe fundamental core of remote sensing technology is electromagnetism, the interactions of electromagnetic energy with the atmosphere and the Earth’s surface are critical in determining the quality and type of data collected. The electromagnetic spectrum highlights the diverse range of electromagnetic waves, from long radio waves to short gamma rays, and the human eye’s ability to detect only a small portion of this spectrum, known as visible light. \nPresented below are several prevalent electromagnetic waves utilized in the field of remote sensing, along with their respective applications and examples of corresponding remote sensing satellites.\n\nVisible Light and Near-Infrared: These bands are commonly used for monitoring land cover, vegetation health, urban planning, and environmental changes. Vegetation is strongly reflected in these bands, making it possible to assess the health and density of vegetation. Satellite Examples: Landsat Series: For global environmental monitoring, including agriculture, and forest coverage. Sentinel-2: Providing high-resolution images of land cover and vegetation health.\nThermal Infrared: Used for measuring surface temperature, fire detection, evapotranspiration, and sea surface temperature monitoring. Thermal infrared data can help analyze drought conditions and the urban heat island effect. Satellite Examples: MODIS: Onboard the Terra and Aqua satellites, providing global climate system observations, including surface temperature.\nMicrowave: As microwaves can penetrate clouds, dust, smoke, snow, and rain, they are ideal for satellite communication in extreme weather conditions. Microwave remote sensing is crucial for understanding global water cycles and climate change. Satellite Examples: SMAP (Soil Moisture Active Passive): A NASA satellite focused on global soil moisture measurement to help forecast floods and droughts. GRACE (Gravity Recovery and Climate Experiment) Series: To measure variations in Earth’s gravitational field and deduce changes in ice mass and groundwater storage.\nUltraviolet: Mainly used for atmospheric and solar studies, including ozone layer monitoring, solar activity observation, and air quality assessment. Satellite Examples: Aura Satellite: Carrying the OMI (Ozone Monitoring Instrument) focused on atmospheric composition and atmospheric chemistry studies.\nX-Rays and Gamma Rays: Mainly employed in the field of astronomy to investigate high-energy events in the universe, such as black holes, neutron stars, and remnants of supernovas. Satellite Examples: Chandra X-ray Observatory: For studying high-temperature objects and X-ray sources in the universe.\n\nAs we can see above, with the cornerstone of electromagnetic technology, remote sensing can be utilized across interdisciplinary fields, especially contributing significant power to urban-related studies. For urban environments, the differentiation between wavelengths allows for the identification of specific gases in the atmosphere, which can be used to monitor air quality or track the movement of atmospheric pollutants. In terms of Urban Agriculture, it enables the identification of healthy versus stressed vegetation, allowing for precise monitoring of crop health and the optimization of agricultural practices. Within the field of Urban Planning, it provides critical data for urban planning, such as land use classification and urban expansion. As for Urban Climate Studies, remote sensing data contribute to understanding and modelling climate systems and tracking changes in ice cover, sea levels, and global temperatures.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1 - Intro to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "week1.html#reflection",
    "href": "week1.html#reflection",
    "title": "1  Week 1 - Intro to Remote Sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nBased on my interest in the Internet of Things (IoT), I have developed some ideas about the relationship between remote sensing and IoT. In my view, the development of the two disciplines, remote sensing and IoT, is blurring the distance between them. Both technologies are driven by similar needs- to efficiently collect data on a large scale without requiring a lot of manpower. They have both evolved to be able to analyse data and simplify large amounts of data to make it easy to understand.\nBased on what I’ve learnt about remote sensing this week, I believe that remote sensing and the Internet of Things are essentially complementary and that they have different strengths for solving problems. Remote sensing can essentially be thought of as “external IoT”, whereas traditional IoT uses embedded or internal sensors. Combining the two offers even greater potential. For example, sensors inside an underground pipe may detect a drop in pressure at a certain cross-section, but external hyperspectral sensors can link this pressure to changes present in the ground and synthesise the root cause of the problem. The data generated by these technologies has the potential to provide a wide range of new insights, reduce costs and improve system performance.\nWith their combination, plus the utilisation of new technologies such as artificial intelligence and cloud computing. There is an opportunity for a whole host of new ways to protect critical infrastructure, preserve the environment and improve human life.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1 - Intro to Remote Sensing</span>"
    ]
  },
  {
    "objectID": "week6.html",
    "href": "week6.html",
    "title": "6  week 6 - intro to GEE",
    "section": "",
    "text": "Mind map",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>week 6 - intro to GEE</span>"
    ]
  },
  {
    "objectID": "week3.html#applications",
    "href": "week3.html#applications",
    "title": "3  week 3 - corrections",
    "section": "3.2 Applications",
    "text": "3.2 Applications\nVegetation Indices (VIs) have evolved over the past four decades in the field of remote sensing, becoming essential tools for assessing vegetation. Since the launch of the first Earth Resource Satellite in 1972, scientists have been attempting to establish approximate relationships between spectral responses and vegetation cover(Eastman et al., 2013).\nOver the past two decades, more than forty vegetation indices have been researched and developed, such as the Normalized Difference Vegetation Index (NDVI), Enhanced Vegetation Index (EVI), and Soil-Adjusted Vegetation Index (SAVI).\n\n\n\nEnhanced Vegetation Index World-wide 2011\n\n\nWhile VIs provide a convenient and quick tool for vegetation monitoring, their application is influenced and constrained by factors such as weather conditions, observational conditions of remote sensors, soil moisture, etc. Moreover, in different environmental conditions, the analysis of vegetation indices becomes more complex(Xue & Su, 2017). This also implies that future research should target the vegetation-soil-atmosphere system as a whole, taking into consideration the characteristics of remote sensors and electromagnetic radiation.\nAdditionally, the effectiveness of using VIs for vegetation monitoring greatly depends on the spatial, spectral, and temporal resolution of remote sensing data. Lower resolutions may not accurately capture small-scale vegetation changes, while acquiring high-resolution data can be costly.\nLooking forward to future developments, with the rapid advancement of artificial intelligence and the repeated mention of smart cities, smart agriculture becomes a crucial part of smart cities, where Vegetation Indices can be fully utilized. Integrating multi-temporal satellite and unmanned aerial vehicle (UAV) observational data with field soil, vegetation, and yield observations, soil type maps, elevation maps, historical parcel and crop information, and meteorological data could provide data support for agricultural management, enabling more precise crop management. Furthermore, the introduction of concepts like “Task Map 2.0” and “AgroGIS,” which automatically generate precise crop management instructions, further promotes the practice of ‘Smart Agriculture’(Nicholas et al., 2022).\nHere is an example- Applications of Remote Sensing in Precision Farming:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>week 3 - corrections</span>"
    ]
  },
  {
    "objectID": "week3.html#reflection",
    "href": "week3.html#reflection",
    "title": "3  week 3 - corrections",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\nDue to my interest in the Internet of Things (IoT), in my past explorations I have seen the great potential of IoT and its application to smart agriculture. Through this week’s study, I have realised that remote sensing can also contribute immensely to smart agriculture, and that this interdisciplinary development is an inevitable trend in the development of our present society, and an important way in which we can contribute to the achievement of the goals of the United Nations.\nThere is a remarkable example in practical applications: In Wageningen, Nederland, The National Smart Farming Pilot Project (NPPL) has been established by the Ministry of Agriculture, Nature and Food Quality and Wageningen Plant Research ProAgrica, it aims to combine remote sensing technology and Internet of Things technology to create more productive and intelligent agricultural systems(Wageningen University & Research, 2017).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>week 3 - corrections</span>"
    ]
  },
  {
    "objectID": "week3.html#references",
    "href": "week3.html#references",
    "title": "3  week 3 - corrections",
    "section": "3.4 References",
    "text": "3.4 References\nEastman, J.R., Sangermano, F., Machado, E.A., Rogan, J. and Anyamba, A., 2013. Global trends in seasonality of normalized difference vegetation index (NDVI), 1982–2011. Remote Sens., 5(10), pp.4799-4818. Available at: https://doi.org/10.3390/rs5104799 [Accessed 28 January 2024].\nJensen, J.R., 2015. Introductory Digital Image Processing: A Remote Sensing Perspective. Prentice-Hall Inc., pp.208-273.\nXue, J. and Su, B., 2017. Significant remote sensing vegetation indices: A review of developments and applications. Volume 2017, Article ID 1353691. Available at: https://doi.org/10.1155/2017/1353691 [Accessed 28 January 2024].\nNicholas, N.J.H., Ng, Y.P. and Tew, Y., 2022. Intelligent farming with NDVI integrated agriculture solution. In: 2022 International Conference on Green Energy, Computing and Sustainable Technology (GECOST), Miri Sarawak, Malaysia. IEEE, pp. 342-345. Available at: doi:10.1109/GECOST55694.2022.10010427 [Accessed 28 January 2024].\nSchulte to Bühne, H. and Pettorelli, N., 2018. Better together: Integrating and fusing multispectral and radar satellite imagery to inform biodiversity monitoring, ecological research and conservation science. Methods in Ecology and Evolution, 9, pp.849-865.\nWageningen University & Research, 2017. National Smart Farming pilot project. Available at: https://www.wur.nl/en/project/national-smart-farming-pilot-project.htm [Accessed 28 January 2024].",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>week 3 - corrections</span>"
    ]
  },
  {
    "objectID": "week4.html",
    "href": "week4.html",
    "title": "4  week 4 - policy",
    "section": "",
    "text": "4.1 Overview - Assessing Burn Scars After Bushfire in Sydney\nDo you remember the 2019–20 bushfires in Sydney? You and I were both in Melbourne at the time, and we were also affected\nI do.It was a tragedy. Those people, animals, and plants that lost their lives in the great fire- R.I.P.. Today, let’s explore the application of remote sensing technology in assessing burn scars after bushfire, in conjunction with relevant policies.\nIn today’s world, remote sensing technology has become an important tool for detecting and managing urban challenges, building a bridge between scientific research and policy development.\nBush Fire is one of the most commonly occurring natural disasters in Australia which brings huge damage to the land and requires a relatively long recovery period. Sydney, surrounded by vast tracts of bushland, is inherently vulnerable to the threat of bushfires, which have become more frequent and intense due to climate change and urban encroachment into forested areas. However, considering the scale of the bushfire and human ability, it is hard to examine the post-fire condition manually. Hence Landsat satellites are constantly being used to capture and analyze spatial information on large scales, such as detecting physically affected regions after fire, predicting the potential hazards, generate vegetation regrowth.\nThe significance of post-wildfire assessments in Australia, particularly regarding the evaluation of burn scars, is underscored by the “National Bushfire Management Policy Statement for Forests and Rangelands” (2014). “Planning for Bush Fire Protection 2019” further complements this approach by providing detailed guidelines for post-bushfire planning.\nBy assessing the burn scars left by bushfires, we can gain a better understanding of the environmental impact of fires and provide critical information for rebuilding and restoration efforts, which is significant for achieving the United Nations Sustainable Development Goals.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>week 4 - policy</span>"
    ]
  },
  {
    "objectID": "week4.html#overview---assessing-burn-scars-after-bushfire-in-sydney",
    "href": "week4.html#overview---assessing-burn-scars-after-bushfire-in-sydney",
    "title": "4  week 4 - policy",
    "section": "",
    "text": "Goal 13: Climate Action - Monitoring and assessing the aftermath of fires can improve our understanding of how climate change affects the frequency and intensity of wildfires, leading to better adaptation and mitigation strategies.\nGoal 15: Life on Land - Evaluating the extent of ecosystem damage through burn scar assessments helps in taking appropriate restoration and conservation measures, protecting terrestrial ecosystems and biodiversity.\nGoal 11: Sustainable Cities and Communities - Assessing burn scars is also related to reducing disaster risk and enhancing disaster response capabilities (such as to wildfires), crucial for protecting human settlements and ensuring the sustainability of cities and communities.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>week 4 - policy</span>"
    ]
  },
  {
    "objectID": "week4.html#applications",
    "href": "week4.html#applications",
    "title": "4  week 4 - policy",
    "section": "4.2 Applications",
    "text": "4.2 Applications\nThe importance of accurately assessing burn scars extends beyond ecological concerns; it directly influences post-disaster reconstruction and mitigation strategies. By understanding the severity of wildfires and the specific areas most affected, policymakers and urban planners can prioritize rehabilitation efforts, allocate resources more efficiently, and implement land management practices aimed at reducing the risk of future fires. Furthermore, the integration of fire severity patterns with vegetation type data can improve the accuracy of fire intensity inferences, aiding in the refinement of fire management policies and practices.\nNext, I will practice examining the burn severity and scars of the bushfire that took place in Kosciusko National Park, New South Wales between the end of 2019 and the beginning of 2020 through a range of applications using Landsat 8 datasets. This will be more helpful to your understanding of burn scar evaluation and related policy formulation.\nLast week we talked about NDVI, Today we explore another index. The Burn Area Index (BAI) is an important element for analyzing burn scars, which uses the reflectance values in the red and NIR (Near Infrared) portion of the spectrum to identify the areas of the terrain affected by fire(Mashhadi & Alganci, 2021).\n\n\n\nPre-fire BAI(lest) VS. Post-fire BAI(right)\n\n\nIn above images, the white pixels indicate the area that has been burned, while the darker pixels indicate the presence of healthy vegetation.\nFor other visualization, Normalized Burn Ratio Images show below:\n\n\n\nPre-fire NBR(lest) VS. Post-fire NBR(right)\n\n\nNBR is determined by utilizing wavelengths in the near infrared and shortwave infrared spectrum. The presence of a burnt area is indicated by a higher nominalized burn ratio, as burnt vegetation exhibits a lower near infrared reflectance and a higher shortwave infrared wavelength. In contrast, healthy vegetation displays the opposite characteristics. Therefore, the darker region with a low NBR value indicates the burnt area.\nNext, By utilizing the Float(b2-b1) function, where b2 represents the NBR image before the fire and b1 represents the NBR image after the fire, I calculated the difference between the pre and post fire NBR images. The image highlights burnt areas, which are represented by white pixels. The severity of burn scars is indicated by the higher clarity and brightness of the white pixels.\n\n\n\nDifferenced Normalized Burn Ratio Image\n\n\nFinally, I created a burn severity map. Using the U.S. Geological Survey’s FIREMON program’s burn severity categories as a guide, creating seven levels of severity in order to visually represent them.\n\n\n\nMap of Fire Severity\n\n\nBased on the map above, it provides better visualisation to assess the burn scars, relevant policymakers such as the NSW Government and the Department of Planning and Environment can more accurately deploy post-disaster policies. Potential policies may be as follows:\n\nReconstruction and Recovery Policy: Based on the severity maps of forest burn scars, the government can develop specific forest restoration plans, including reforestation and ecosystem rebuilding, to facilitate the natural recovery of damaged areas.\nPrevention and Disaster Mitigation Policy: Utilizing burn scar severity maps to identify high-risk areas, the government can implement preventive measures in these areas, such as establishing firebreaks and enhancing monitoring and early warning system capabilities.\nLand Use and Planning Policy: Based on the distribution and severity of burned areas, land use planning can be adjusted to limit development in high-risk areas and protect areas of flammable vegetation from being disturbed.\nFunding Allocation and Resource Distribution Policy: Resources and funding should be prioritized for areas most severely affected by burns, as indicated by the burn scar severity maps, to support emergency response, recovery, and prevention efforts.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>week 4 - policy</span>"
    ]
  },
  {
    "objectID": "week4.html#literature-review-and-reflection",
    "href": "week4.html#literature-review-and-reflection",
    "title": "4  week 4 - policy",
    "section": "4.3 Literature Review and Reflection",
    "text": "4.3 Literature Review and Reflection\nThe increasing emphasis on sustainability in all facets of urban development and management has encouraged the use and progress of remote sensing technology in city-related applications. However, the integration among remote sensing, ecology, and urban planning disciplines remains limited, with only 12% of the studies achieving a comprehensive integration of knowledge across these three fields(Wellmann et al., 2020). Most research primarily aims to expand the knowledge base or monitor the impact of existing policies, with few studies directly related to policy, such as providing concrete recommendations or evaluations for planning issues. Therefore, in the future, overcoming information barriers, the necessity of interdisciplinary integration, and enhancing the application of remote sensing knowledge throughout the policy cycle are critical considerations for policymakers and technologists(Kadhim, Mourshed & Bray, 2016).\nMy mini applications serves merely as a conceptual demonstration of assessing wildfire damage using remote sensing data and cannot act as a direct indicator for policy recommendations. In the real world, it is essential to consider a broader range of factors, such as economics, botany, and biology. This reflects the complexity of policy-making, indicating that any tech or Method can only assist in the process- the true wisdom lies in finding a balance among complex, interdisciplinary factors.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>week 4 - policy</span>"
    ]
  }
]